{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Sonar Data\n",
    "\n",
    "Overview: Data set [description](http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)\n",
    "\n",
    "Predictors are attributes named `X1` through `X60`.  Response variable is `target`.\n",
    "\n",
    "Objective: develop feed-forward neural network to predict the `target`.\n",
    "\n",
    "Algorithm: [MLPClassifer](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=MLPClassifier)\n",
    "\n",
    "sklearn neural network [user guide](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORDS FOR THE DAY: MEDA IS GREAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# read in csv file\n",
    "#\n",
    "raw = pd.read_csv('./data/sonar.csv')\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1      X2      X3      X4      X5      X6      X7      X8      X9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      X10  ...     X52     X53     X54     X55     X56     X57     X58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      X59     X60  target  \n",
       "0  0.0090  0.0032       R  \n",
       "1  0.0052  0.0044       R  \n",
       "2  0.0095  0.0078       R  \n",
       "3  0.0040  0.0117       R  \n",
       "4  0.0107  0.0094       R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display sample\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>X1</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X2</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.03080</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.2339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X3</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.03430</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X4</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.04405</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.4264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X5</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X6</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.09215</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.3823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X7</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.10695</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X8</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X9</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.15225</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.6828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X10</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>0.18240</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X11</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.236013</td>\n",
       "      <td>0.132705</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.129250</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.301650</td>\n",
       "      <td>0.7342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X12</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.250221</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.24905</td>\n",
       "      <td>0.331250</td>\n",
       "      <td>0.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X13</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.273305</td>\n",
       "      <td>0.140962</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.166125</td>\n",
       "      <td>0.26395</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>0.7131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X14</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.296568</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.175175</td>\n",
       "      <td>0.28110</td>\n",
       "      <td>0.386175</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X15</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.320201</td>\n",
       "      <td>0.205427</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.164625</td>\n",
       "      <td>0.28170</td>\n",
       "      <td>0.452925</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X16</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.378487</td>\n",
       "      <td>0.232650</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.30470</td>\n",
       "      <td>0.535725</td>\n",
       "      <td>0.9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X17</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.415983</td>\n",
       "      <td>0.263677</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.205850</td>\n",
       "      <td>0.30840</td>\n",
       "      <td>0.659425</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X18</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.452318</td>\n",
       "      <td>0.261529</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.242075</td>\n",
       "      <td>0.36830</td>\n",
       "      <td>0.679050</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X19</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.504812</td>\n",
       "      <td>0.257988</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.299075</td>\n",
       "      <td>0.43495</td>\n",
       "      <td>0.731400</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X20</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.563047</td>\n",
       "      <td>0.262653</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.350625</td>\n",
       "      <td>0.54250</td>\n",
       "      <td>0.809325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X21</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.609060</td>\n",
       "      <td>0.257818</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.399725</td>\n",
       "      <td>0.61770</td>\n",
       "      <td>0.816975</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X22</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.624275</td>\n",
       "      <td>0.255883</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.406925</td>\n",
       "      <td>0.66490</td>\n",
       "      <td>0.831975</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X23</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.646975</td>\n",
       "      <td>0.250175</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.450225</td>\n",
       "      <td>0.69970</td>\n",
       "      <td>0.848575</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X24</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.672654</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.540725</td>\n",
       "      <td>0.69850</td>\n",
       "      <td>0.872175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X25</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.675424</td>\n",
       "      <td>0.244926</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.72110</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X26</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.699866</td>\n",
       "      <td>0.237228</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.544175</td>\n",
       "      <td>0.75450</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X27</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.702155</td>\n",
       "      <td>0.245657</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.531900</td>\n",
       "      <td>0.74560</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X28</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.694024</td>\n",
       "      <td>0.237189</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.534775</td>\n",
       "      <td>0.73190</td>\n",
       "      <td>0.900275</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X29</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.642074</td>\n",
       "      <td>0.240250</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.68080</td>\n",
       "      <td>0.852125</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X30</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.580928</td>\n",
       "      <td>0.220749</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.60715</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X31</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.504475</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.345550</td>\n",
       "      <td>0.49035</td>\n",
       "      <td>0.641950</td>\n",
       "      <td>0.9657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X32</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.439040</td>\n",
       "      <td>0.213237</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.42960</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.9306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X33</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.417220</td>\n",
       "      <td>0.206513</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.257875</td>\n",
       "      <td>0.39120</td>\n",
       "      <td>0.556125</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X34</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.403233</td>\n",
       "      <td>0.231242</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.217575</td>\n",
       "      <td>0.35105</td>\n",
       "      <td>0.596125</td>\n",
       "      <td>0.9647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X35</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.392571</td>\n",
       "      <td>0.259132</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.179375</td>\n",
       "      <td>0.31275</td>\n",
       "      <td>0.593350</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X36</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.384848</td>\n",
       "      <td>0.264121</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.154350</td>\n",
       "      <td>0.32115</td>\n",
       "      <td>0.556525</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X37</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.363807</td>\n",
       "      <td>0.239912</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.30630</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X38</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.339657</td>\n",
       "      <td>0.212973</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.174275</td>\n",
       "      <td>0.31270</td>\n",
       "      <td>0.440550</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X39</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>0.199075</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.173975</td>\n",
       "      <td>0.28350</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.9857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X40</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.311207</td>\n",
       "      <td>0.178662</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.186450</td>\n",
       "      <td>0.27805</td>\n",
       "      <td>0.424350</td>\n",
       "      <td>0.9297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X41</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.289252</td>\n",
       "      <td>0.171111</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.25950</td>\n",
       "      <td>0.387525</td>\n",
       "      <td>0.8995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X42</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.278293</td>\n",
       "      <td>0.168728</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.24510</td>\n",
       "      <td>0.384250</td>\n",
       "      <td>0.8246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X43</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.246542</td>\n",
       "      <td>0.138993</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.22255</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>0.7733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X44</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.214075</td>\n",
       "      <td>0.133291</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.126875</td>\n",
       "      <td>0.17770</td>\n",
       "      <td>0.271750</td>\n",
       "      <td>0.7762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X45</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.197232</td>\n",
       "      <td>0.151628</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.094475</td>\n",
       "      <td>0.14800</td>\n",
       "      <td>0.231550</td>\n",
       "      <td>0.7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X46</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.160631</td>\n",
       "      <td>0.133938</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.068550</td>\n",
       "      <td>0.12135</td>\n",
       "      <td>0.200375</td>\n",
       "      <td>0.7292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X47</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.122453</td>\n",
       "      <td>0.086953</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.064250</td>\n",
       "      <td>0.10165</td>\n",
       "      <td>0.154425</td>\n",
       "      <td>0.5522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X48</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.091424</td>\n",
       "      <td>0.062417</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.045125</td>\n",
       "      <td>0.07810</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.3339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X49</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.051929</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.026350</td>\n",
       "      <td>0.04470</td>\n",
       "      <td>0.068525</td>\n",
       "      <td>0.1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X50</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.01790</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X51</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.01390</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X52</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.01140</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.0709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X53</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.00955</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X54</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X55</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X56</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.00685</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.0394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X57</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.00595</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X58</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.00580</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X59</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.00640</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X60</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.00530</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      mean       std     min       25%      50%       75%     max\n",
       "X1   208.0  0.029164  0.022991  0.0015  0.013350  0.02280  0.035550  0.1371\n",
       "X2   208.0  0.038437  0.032960  0.0006  0.016450  0.03080  0.047950  0.2339\n",
       "X3   208.0  0.043832  0.038428  0.0015  0.018950  0.03430  0.057950  0.3059\n",
       "X4   208.0  0.053892  0.046528  0.0058  0.024375  0.04405  0.064500  0.4264\n",
       "X5   208.0  0.075202  0.055552  0.0067  0.038050  0.06250  0.100275  0.4010\n",
       "X6   208.0  0.104570  0.059105  0.0102  0.067025  0.09215  0.134125  0.3823\n",
       "X7   208.0  0.121747  0.061788  0.0033  0.080900  0.10695  0.154000  0.3729\n",
       "X8   208.0  0.134799  0.085152  0.0055  0.080425  0.11210  0.169600  0.4590\n",
       "X9   208.0  0.178003  0.118387  0.0075  0.097025  0.15225  0.233425  0.6828\n",
       "X10  208.0  0.208259  0.134416  0.0113  0.111275  0.18240  0.268700  0.7106\n",
       "X11  208.0  0.236013  0.132705  0.0289  0.129250  0.22480  0.301650  0.7342\n",
       "X12  208.0  0.250221  0.140072  0.0236  0.133475  0.24905  0.331250  0.7060\n",
       "X13  208.0  0.273305  0.140962  0.0184  0.166125  0.26395  0.351250  0.7131\n",
       "X14  208.0  0.296568  0.164474  0.0273  0.175175  0.28110  0.386175  0.9970\n",
       "X15  208.0  0.320201  0.205427  0.0031  0.164625  0.28170  0.452925  1.0000\n",
       "X16  208.0  0.378487  0.232650  0.0162  0.196300  0.30470  0.535725  0.9988\n",
       "X17  208.0  0.415983  0.263677  0.0349  0.205850  0.30840  0.659425  1.0000\n",
       "X18  208.0  0.452318  0.261529  0.0375  0.242075  0.36830  0.679050  1.0000\n",
       "X19  208.0  0.504812  0.257988  0.0494  0.299075  0.43495  0.731400  1.0000\n",
       "X20  208.0  0.563047  0.262653  0.0656  0.350625  0.54250  0.809325  1.0000\n",
       "X21  208.0  0.609060  0.257818  0.0512  0.399725  0.61770  0.816975  1.0000\n",
       "X22  208.0  0.624275  0.255883  0.0219  0.406925  0.66490  0.831975  1.0000\n",
       "X23  208.0  0.646975  0.250175  0.0563  0.450225  0.69970  0.848575  1.0000\n",
       "X24  208.0  0.672654  0.239116  0.0239  0.540725  0.69850  0.872175  1.0000\n",
       "X25  208.0  0.675424  0.244926  0.0240  0.525800  0.72110  0.873725  1.0000\n",
       "X26  208.0  0.699866  0.237228  0.0921  0.544175  0.75450  0.893800  1.0000\n",
       "X27  208.0  0.702155  0.245657  0.0481  0.531900  0.74560  0.917100  1.0000\n",
       "X28  208.0  0.694024  0.237189  0.0284  0.534775  0.73190  0.900275  1.0000\n",
       "X29  208.0  0.642074  0.240250  0.0144  0.463700  0.68080  0.852125  1.0000\n",
       "X30  208.0  0.580928  0.220749  0.0613  0.411400  0.60715  0.735175  1.0000\n",
       "X31  208.0  0.504475  0.213992  0.0482  0.345550  0.49035  0.641950  0.9657\n",
       "X32  208.0  0.439040  0.213237  0.0404  0.281400  0.42960  0.580300  0.9306\n",
       "X33  208.0  0.417220  0.206513  0.0477  0.257875  0.39120  0.556125  1.0000\n",
       "X34  208.0  0.403233  0.231242  0.0212  0.217575  0.35105  0.596125  0.9647\n",
       "X35  208.0  0.392571  0.259132  0.0223  0.179375  0.31275  0.593350  1.0000\n",
       "X36  208.0  0.384848  0.264121  0.0080  0.154350  0.32115  0.556525  1.0000\n",
       "X37  208.0  0.363807  0.239912  0.0351  0.160100  0.30630  0.518900  0.9497\n",
       "X38  208.0  0.339657  0.212973  0.0383  0.174275  0.31270  0.440550  1.0000\n",
       "X39  208.0  0.325800  0.199075  0.0371  0.173975  0.28350  0.434900  0.9857\n",
       "X40  208.0  0.311207  0.178662  0.0117  0.186450  0.27805  0.424350  0.9297\n",
       "X41  208.0  0.289252  0.171111  0.0360  0.163100  0.25950  0.387525  0.8995\n",
       "X42  208.0  0.278293  0.168728  0.0056  0.158900  0.24510  0.384250  0.8246\n",
       "X43  208.0  0.246542  0.138993  0.0000  0.155200  0.22255  0.324525  0.7733\n",
       "X44  208.0  0.214075  0.133291  0.0000  0.126875  0.17770  0.271750  0.7762\n",
       "X45  208.0  0.197232  0.151628  0.0000  0.094475  0.14800  0.231550  0.7034\n",
       "X46  208.0  0.160631  0.133938  0.0000  0.068550  0.12135  0.200375  0.7292\n",
       "X47  208.0  0.122453  0.086953  0.0000  0.064250  0.10165  0.154425  0.5522\n",
       "X48  208.0  0.091424  0.062417  0.0000  0.045125  0.07810  0.120100  0.3339\n",
       "X49  208.0  0.051929  0.035954  0.0000  0.026350  0.04470  0.068525  0.1981\n",
       "X50  208.0  0.020424  0.013665  0.0000  0.011550  0.01790  0.025275  0.0825\n",
       "X51  208.0  0.016069  0.012008  0.0000  0.008425  0.01390  0.020825  0.1004\n",
       "X52  208.0  0.013420  0.009634  0.0008  0.007275  0.01140  0.016725  0.0709\n",
       "X53  208.0  0.010709  0.007060  0.0005  0.005075  0.00955  0.014900  0.0390\n",
       "X54  208.0  0.010941  0.007301  0.0010  0.005375  0.00930  0.014500  0.0352\n",
       "X55  208.0  0.009290  0.007088  0.0006  0.004150  0.00750  0.012100  0.0447\n",
       "X56  208.0  0.008222  0.005736  0.0004  0.004400  0.00685  0.010575  0.0394\n",
       "X57  208.0  0.007820  0.005785  0.0003  0.003700  0.00595  0.010425  0.0355\n",
       "X58  208.0  0.007949  0.006470  0.0003  0.003600  0.00580  0.010350  0.0440\n",
       "X59  208.0  0.007941  0.006181  0.0001  0.003675  0.00640  0.010325  0.0364\n",
       "X60  208.0  0.006507  0.005031  0.0006  0.003100  0.00530  0.008525  0.0439"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Descriptive statistics for predictors\n",
    "#\n",
    "raw.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Overview of target variable\n",
    "#\n",
    "raw.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    0.533654\n",
       "R    0.466346\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Calculate fraction of each response value\n",
    "#\n",
    "raw.target.value_counts()/raw.target.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 predictors: ['X1', 'X2', 'X3', 'X4', 'X5']\n",
      "\n",
      "last 5 predictors: ['X56', 'X57', 'X58', 'X59', 'X60']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# create dataframe containing only predictors X1 through X60\n",
    "#\n",
    "\n",
    "# generate predictor names\n",
    "predictors = ['X'+str(n) for n in range(1,61)]\n",
    "\n",
    "print('first 5 predictors:', predictors[:5])\n",
    "print('\\nlast 5 predictors:',predictors[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1      X2      X3      X4      X5      X6      X7      X8      X9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      X10  ...     X51     X52     X53     X54     X55     X56     X57  \\\n",
       "0  0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
       "1  0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "2  0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "3  0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "4  0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "\n",
       "      X58     X59     X60  \n",
       "0  0.0084  0.0090  0.0032  \n",
       "1  0.0049  0.0052  0.0044  \n",
       "2  0.0164  0.0095  0.0078  \n",
       "3  0.0044  0.0040  0.0117  \n",
       "4  0.0048  0.0107  0.0094  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data frame\n",
    "raw_X = raw.loc[:,predictors]\n",
    "raw_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.533654\n",
       "0    0.466346\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# translate response attribute from 'M'/'R' to 1/0\n",
    "#\n",
    "raw_y = raw.target.map(dict(M=1,R=0))\n",
    "raw_y.value_counts()/raw_y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# 70%/30% split train/test data set\n",
    "# set random seed for repeatability\n",
    "#\n",
    "train_X, test_X, train_y, test_y = train_test_split(raw_X, raw_y, test_size=0.3, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training response attribute profile\n",
      " 1    0.531034\n",
      "0    0.468966\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('training response attribute profile\\n',train_y.value_counts()/train_y.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test response attribute profile\n",
      " 1    0.539683\n",
      "0    0.460317\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('test response attribute profile\\n', test_y.value_counts()/test_y.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# define neural network model architecture\n",
    "# one hidden layer with 10 nodes\n",
    "#\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10,),max_iter=2000, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=31, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# fit model to training data\n",
    "#\n",
    "nn.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.84%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}%'.format(100 * accuracy_score(test_y,nn.predict(test_X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Try standardizing the predictors\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=31, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# refit model with standardized predictors\n",
    "#\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10,),max_iter=2000, random_state=31)\n",
    "\n",
    "# transform predictors into standardize form\n",
    "ss_train_X = ss.fit_transform(train_X)\n",
    "\n",
    "# train model\n",
    "nn.fit(ss.fit_transform(train_X),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.02%\n"
     ]
    }
   ],
   "source": [
    "# transform test data into standardized form\n",
    "ss_test_X = ss.transform(test_X)\n",
    "\n",
    "# check accuracy for standardized predictors\n",
    "print('accuracy: {:.2f}%'.format(100*accuracy_score(test_y,nn.predict(ss_test_X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test alternative network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# define network alternatives\n",
    "#\n",
    "hidden_layers = [\n",
    "    (10,), # 1 hidden layer, 10 nodes\n",
    "    (20,), # 1 hidden layer, 20 nodes\n",
    "    (50,), # 1 hidden layer, 50 nodes\n",
    "    (100,), # 1 hidden layer, 100 nodes\n",
    "    (25,25), # 2 hidden layers, 25 nodes/25 nodes\n",
    "    (40,40), # 2 hidden layers, 40 nodes/40 nodes\n",
    "    (50, 25), # 2 hidden layers, 50 nodes/25 nodes\n",
    "    (25,25,25), # 3 hidden layers, 25 nodes/ 25 nodes/ 25 nodes\n",
    "    (10,10,10), # 3 hidden layers, 10 nodes/ 10 nodes/ 10 nodes\n",
    "    (25,25,25,25) # 4 hidden layers, 25 nodes/ 25 nodes/ 25 nodes/ 25 nodes\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hidden layer: (10,)\n",
      "\taccuracy: 73.02%\n",
      "\n",
      "hidden layer: (20,)\n",
      "\taccuracy: 74.60%\n",
      "\n",
      "hidden layer: (50,)\n",
      "\taccuracy: 76.19%\n",
      "\n",
      "hidden layer: (100,)\n",
      "\taccuracy: 73.02%\n",
      "\n",
      "hidden layer: (25, 25)\n",
      "\taccuracy: 77.78%\n",
      "\n",
      "hidden layer: (40, 40)\n",
      "\taccuracy: 76.19%\n",
      "\n",
      "hidden layer: (50, 25)\n",
      "\taccuracy: 69.84%\n",
      "\n",
      "hidden layer: (25, 25, 25)\n",
      "\taccuracy: 76.19%\n",
      "\n",
      "hidden layer: (10, 10, 10)\n",
      "\taccuracy: 74.60%\n",
      "\n",
      "hidden layer: (25, 25, 25, 25)\n",
      "\taccuracy: 76.19%\n"
     ]
    }
   ],
   "source": [
    "# try each network alternatives\n",
    "results = []\n",
    "for hls in hidden_layers:\n",
    "    \n",
    "    # print hidden layer specification\n",
    "    print('\\nhidden layer: {}'.format(hls))\n",
    "    \n",
    "    # define neural network model\n",
    "    nn = MLPClassifier(hidden_layer_sizes=hls, max_iter=2000, random_state=31)\n",
    "    \n",
    "    # fit model\n",
    "    nn.fit(ss_train_X, train_y)\n",
    "    \n",
    "    # test model\n",
    "    test_accuracy = 100*accuracy_score(test_y,nn.predict(ss_test_X))\n",
    "    print('\\taccuracy: {:.2f}%'.format(test_accuracy))\n",
    "    \n",
    "    # keep track of test results\n",
    "    results.append(dict(hidden_layer=hls, test_accuracy=test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(25, 25)</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(40, 40)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>(25, 25, 25)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(25, 25, 25, 25)</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>74.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(10, 10, 10)</td>\n",
       "      <td>74.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>73.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>73.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>(50, 25)</td>\n",
       "      <td>69.841270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hidden_layer  test_accuracy\n",
       "4          (25, 25)      77.777778\n",
       "2             (50,)      76.190476\n",
       "5          (40, 40)      76.190476\n",
       "7      (25, 25, 25)      76.190476\n",
       "9  (25, 25, 25, 25)      76.190476\n",
       "1             (20,)      74.603175\n",
       "8      (10, 10, 10)      74.603175\n",
       "0             (10,)      73.015873\n",
       "3            (100,)      73.015873\n",
       "6          (50, 25)      69.841270"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# convert test results into data frame\n",
    "#\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.sort_values(by=['test_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test Data Set Performance')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#\n",
    "# plot test data results\n",
    "#\n",
    "result_df.sort_values(by=['test_accuracy'],ascending=[True],inplace=True)\n",
    "ax = result_df.plot('hidden_layer','test_accuracy','barh',\n",
    "                    figsize=(9,7),\n",
    "                    legend=False)\n",
    "ax.set_xlabel('Accuracy Percent')\n",
    "ax.set_title('Test Data Set Performance',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
